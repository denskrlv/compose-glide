{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff2c664",
   "metadata": {},
   "source": [
    "# Image Generation for Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf25718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from compose_glide import ComposeGlide\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad099de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ComposeGLIDE Instance Configuration             \n",
      "============================================================\n",
      "Device:                        mps                         \n",
      "Verbose:                       True                        \n",
      "------------------------------------------------------------\n",
      "Base Model                                                  \n",
      "  Parameters:                  385,030,726                 \n",
      "  FP16 Enabled:                False                       \n",
      "  Timestep Respacing:          100                         \n",
      "  Image Size:                  64                          \n",
      "------------------------------------------------------------\n",
      "Upsampler Model                                             \n",
      "  Parameters:                  398,361,286                 \n",
      "  FP16 Enabled:                False                       \n",
      "  Timestep Respacing:          fast27                      \n",
      "  Image Size:                  256                         \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "compositional_prompts = [\n",
    "    \"No Smiling AND NOT Glasses AND NOT Female\",\n",
    "    \"Smiling AND NOT (No Glasses) AND NOT Female\",\n",
    "    \"NOT (No Smiling) AND No Glasses AND NOT Male\",\n",
    "    \"NOT (No Smiling) AND NOT (No Glasses) AND Male\",\n",
    "    \"Smiling AND NOT (No Glasses) AND NOT Male\"\n",
    "]\n",
    "\n",
    "NUM_VARIANTS = 20\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"Convert a PyTorch tensor to a PIL Image.\"\"\"\n",
    "    # Scale from [-1, 1] to [0, 255]\n",
    "    scaled = ((tensor + 1) * 127.5).round().clamp(0, 255).to(torch.uint8).cpu()\n",
    "    \n",
    "    # Rearrange dimensions from CxHxW to HxWxC\n",
    "    if scaled.dim() == 3:  # Single image\n",
    "        img = scaled.permute(1, 2, 0).numpy()\n",
    "    else:  # Batch of images\n",
    "        img = scaled[0].permute(1, 2, 0).numpy()  # Take the first image\n",
    "        \n",
    "    return Image.fromarray(img)\n",
    "\n",
    "compose_glide = ComposeGlide(model_name='glide_faces', verbose=True)\n",
    "print(compose_glide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f26073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded from cache: clip_model_cache\n",
      "Using prompts: ['smiling', 'glasses', 'female'] with weights: [-5.765088810096396, -6.084469064436272, -6.1504421254673325]\n",
      "Generating base image 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5990be0f71924e55948dfd1ccebc4755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsampling base image 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d538993a0f4187997ac0d6864209f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/deniskrylov/Developer/University/compose-glide/outputs/prompt_0_variant_0.png!\n"
     ]
    }
   ],
   "source": [
    "for i, prompt in enumerate(compositional_prompts):\n",
    "    for j in range(NUM_VARIANTS):\n",
    "        result, _ = compose_glide.generate(\n",
    "            prompt, \n",
    "            num_images=1, \n",
    "            upsample=True, \n",
    "            upsample_temp=0.995,\n",
    "            save_intermediate_steps=10,\n",
    "            return_attention_maps=True\n",
    "        )\n",
    "\n",
    "        image = tensor_to_image(result)\n",
    "        image_path = f\"/Users/deniskrylov/Developer/University/compose-glide/outputs/prompt_{i}_variant_{j}.png\"\n",
    "        image.save(image_path)\n",
    "        print(f\"Saved: {image_path}!\")\n",
    "        \n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
